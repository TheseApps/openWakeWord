<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Websocket Microphone Streaming</title>
  <style>
    body {
      text-align: center;
      font-family: 'Roboto', sans-serif;
    }
    #startButton {
      padding: 15px 30px;
      font-size: 18px;
      background-color: #03A9F4;
      border: none;
      border-radius: 4px;
      color: white;
      cursor: pointer;
      outline: none;
      transition: background-color 0.3s;
    }
    #startButton.listening {
      background-color: #F44336;
    }

    #statusIndicator {
      margin: 10px auto;
      padding: 5px;
      border-radius: 4px;
      background-color: #f0f0f0;
      max-width: 400px;
    }

    #recordingStatus {
      margin: 10px auto;
      padding: 10px;
      border-radius: 4px;
      max-width: 400px;
      background-color: #f0f0f0;
      display: none;
    }

    #recordingStatus.active {
      display: block;
      background-color: #FF5722;
      color: white;
      animation: pulse 2s infinite;
    }

    @keyframes pulse {
      0% { opacity: 0.8; }
      50% { opacity: 1; }
      100% { opacity: 0.8; }
    }

    table {
      margin: 20px auto;
      border-collapse: collapse;
      width: 60%;
    }
    th, td {
      border: 1px solid #E0E0E0;
      padding: 10px;
      text-align: left;
    }
    th {
      background-color: #F5F5F5;
    }

    #recordings {
      margin: 20px auto;
      max-width: 80%;
      text-align: left;
    }

    .recording-item {
      margin: 10px 0;
      padding: 10px;
      background-color: #f5f5f5;
      border-radius: 4px;
    }

    @keyframes fadeOut {
      from {
        opacity: 1;
      }
      to {
        opacity: 0;
      }
    }

    .detected-animation {
      animation: fadeOut 2s forwards;
    }
  </style>
</head>
<body>
  <h1>Streaming Audio to openWakeWord Using Websockets</h1>
  <button id="startButton">Start Listening</button>
  <div id="statusIndicator">Status: Not connected</div>
  <div id="recordingStatus">Recording after wake word detection...</div>

  <table>
    <tr>
      <th>Wakeword</th>
      <th>Detected</th>
    </tr>
    <tr>
      <td></td>
      <td></td>
    </tr>
  </table>

  <div id="recordings">
    <h2>Saved Recordings</h2>
    <div id="recordingsList"></div>
  </div>

  <script>
  // State variables
  let isListening = false;
  let isRecording = false;
  let wsReconnectTimeout = null;
  let ws = null;

  // Audio variables
  let audioStream = null;
  let audioContext = null;
  let recorder = null;
  let volume = null;
  let sampleRate = null;

  // Define mapping from model names to brightness values
  const modelBrightnessMap = {
    'hey_mycroft_v0.1': 20,
    'hey_jarvis_v0.1': 200,
    'alexa_v0.1': 'cookie monster' // Intentionally incorrect value for testing
    // Add other models here if needed
  };

  // Cooldown tracking for API calls (milliseconds)
  const apiCooldown = 2000; // 2 seconds
  let lastApiCallTimestamp = {}; // Store last call time per model

  // Update status indicator
  function updateStatus(message) {
    document.getElementById('statusIndicator').textContent = `Status: ${message}`;
  }

  // Update recording status
  function updateRecordingStatus(isActive, message = '') {
    const recordingStatus = document.getElementById('recordingStatus');
    
    if (isActive) {
      recordingStatus.classList.add('active');
      if (message) {
        recordingStatus.textContent = message;
      } else {
        recordingStatus.textContent = 'Recording after wake word detection...';
      }
    } else {
      recordingStatus.classList.remove('active');
    }
    
    isRecording = isActive;
  }

  // Add recording to the list
  function addRecordingToList(filename, trigger, wakeWord) {
    const recordingsList = document.getElementById('recordingsList');
    const recordingItem = document.createElement('div');
    recordingItem.className = 'recording-item';
    
    const now = new Date().toLocaleTimeString();
    recordingItem.innerHTML = `
      <strong>${now}</strong> - Wake word: "${wakeWord}" - 
      Stopped by: ${trigger} - 
      File: ${filename}
    `;
    
    recordingsList.prepend(recordingItem);
  }

  // Set up WebSocket connection with improved error handling and reconnection
  function setupWebSocket() {
    // Clear any pending reconnection
    if (wsReconnectTimeout) {
      clearTimeout(wsReconnectTimeout);
      wsReconnectTimeout = null;
    }
    
    // Close existing connection if open
    if (ws) {
      try {
        ws.close();
      } catch (e) {
        console.error("Error closing existing websocket:", e);
      }
    }
    
    console.log('Setting up WebSocket connection...');
    updateStatus('Connecting...');
    
    // Create new WebSocket connection
    try {
      ws = new WebSocket('ws://localhost:9000/ws');
      
      // When the websocket connection is open
      ws.onopen = function() {
        console.log('WebSocket connection established');
        updateStatus('Connected to server');
        
        // Send sample rate if we're listening
        if (isListening && sampleRate) {
          console.log(`Sending sample rate: ${sampleRate}Hz`);
          ws.send(sampleRate.toString());
        }
      };
      
      // When the websocket connection is closed
      ws.onclose = function(event) {
        console.log(`WebSocket connection closed: Code ${event.code}`);
        updateStatus('Disconnected from server');
        updateRecordingStatus(false);
        
        // Attempt to reconnect if we were listening
        if (isListening) {
          console.log('Attempting to reconnect in 3 seconds...');
          updateStatus('Connection lost. Reconnecting in 3s...');
          wsReconnectTimeout = setTimeout(setupWebSocket, 3000);
        }
      };
      
      // When an error occurs
      ws.onerror = function(error) {
        console.error('WebSocket error:', error);
        updateStatus('Connection error');
      };
      
      // Handle messages from the server
      ws.onmessage = (event) => {
        let model_payload;
        try {
          model_payload = JSON.parse(event.data);
        } catch (e) {
          console.error("Failed to parse JSON:", e, "Raw data:", event.data);
          return; // Stop processing if JSON is invalid
        }

        // Handle loaded models
        if ("loaded_models" in model_payload) {
          // Add loaded models to the rows of the first column in the table, inserting rows as needed
          const table = document.querySelector('table');
          const rows = table.querySelectorAll('tr');
          for (let i = 1; i < model_payload.loaded_models.length + 1; i++) {
            if (i < rows.length) {
              const row = rows[i];
              const cell = row.querySelectorAll('td')[0];
              cell.textContent = model_payload.loaded_models[i - 1];
            } else {
              // Insert extra rows if needed, both column 1 and 2
              const row = table.insertRow();
              const cell1 = row.insertCell();
              const cell2 = row.insertCell();
              cell1.textContent = model_payload.loaded_models[i - 1];
              cell2.textContent = '';
            }
          }
          console.log(`Loaded ${model_payload.loaded_models.length} models`);
          updateStatus('Connected - Models loaded');
        }

        // Handle wake word activations
        if ("activations" in model_payload) {
          const activations = model_payload.activations;
          const scores = model_payload.scores || {};
          
          console.log("Wake word detected!", activations, scores);
          
          // Highlight all activated models in the table
          const table = document.querySelector('table');
          const rows = table.querySelectorAll('tr');
          
          for (let i = 1; i < rows.length; i++) {
            const modelCell = rows[i].querySelectorAll('td')[0];
            const modelName = modelCell.textContent;
            
            if (activations.includes(modelName)) {
              const score = scores[modelName] || 0;
              const cell = rows[i].querySelectorAll('td')[1];
              cell.textContent = `Detected! (${score.toFixed(2)})`;
              cell.classList.add('detected-animation');
              
              // Add announcement
              const recordingStatus = document.getElementById('recordingStatus');
              recordingStatus.textContent = `Wake word detected: ${modelName} (${score.toFixed(2)})`;
              recordingStatus.classList.add('active');
              
              // Auto-hide after 3 seconds
              setTimeout(() => {
                recordingStatus.classList.remove('active');
              }, 3000);
              
              // Remove the CSS class after the animation ends
              cell.addEventListener('animationend', () => {
                cell.textContent = '';
                cell.classList.remove('detected-animation');
              }, { once: true });
            }
          }
        }
      };
    } catch (error) {
      console.error("Error setting up WebSocket:", error);
      updateStatus('Failed to connect');
    }
  }

  // Initialize audio context and capture
  async function initializeAudio() {
    try {
      if (audioContext) {
        return true; // Already initialized
      }
      
      // Get microphone access
      audioStream = await navigator.mediaDevices.getUserMedia({audio: true});
      
      // Create audio context
      const context = window.AudioContext || window.webkitAudioContext;
      audioContext = new context();
      
      // Get sample rate
      sampleRate = audioContext.sampleRate;
      console.log(`Microphone initialized with sample rate: ${sampleRate}Hz`);
      
      // Create gain node
      volume = audioContext.createGain();
      
      // Create audio source
      const audioInput = audioContext.createMediaStreamSource(audioStream);
      
      // Connect source to gain
      audioInput.connect(volume);
      
      // Create script processor with smaller buffer size
      const bufferSize = 1024;  // Reduced for more frequent predictions
      recorder = (audioContext.createScriptProcessor ||
                  audioContext.createJavaScriptNode).call(audioContext,
                                                         bufferSize,
                                                         1,
                                                         1);
      
      // Set up audio processing
      recorder.onaudioprocess = function(event) {
        // Only process if we're listening and websocket is open
        if (isListening && ws && ws.readyState === WebSocket.OPEN) {
          try {
            const samples = event.inputBuffer.getChannelData(0);
            
            // Convert float32 to int16
            const PCM16iSamples = new Int16Array(samples.length);
            
            // Calculate audio level for debugging
            let peakLevel = 0;
            
            for (let i = 0; i < samples.length; i++) {
              // Apply gentle gain boost to improve sensitivity (1.5x)
              const boostedSample = samples[i] * 1.5;
              // Clamp to valid range and convert to int16
              PCM16iSamples[i] = Math.min(32767, Math.max(-32768, Math.round(boostedSample * 32767)));
              
              // Track peak level
              peakLevel = Math.max(peakLevel, Math.abs(PCM16iSamples[i]));
            }
            
            // Log audio levels periodically to help debugging
            if (peakLevel > 10000) {
              console.log(`Audio peak level: ${peakLevel}`);
            }
            
            // Send audio data
            const blob = new Blob([PCM16iSamples], { type: 'application/octet-stream' });
            ws.send(blob);
          } catch (error) {
            console.error('Error processing audio:', error);
          }
        }
      };
      
      return true;
    } catch (error) {
      console.error('Error initializing audio:', error);
      alert('Error accessing microphone. Please check permissions and try again.');
      return false;
    }
  }

  // Start audio streaming
  async function startAudio() {
    try {
      // Initialize audio if needed
      if (!await initializeAudio()) {
        return false;
      }
      
      // Resume audio context if suspended
      if (audioContext && audioContext.state === 'suspended') {
        await audioContext.resume();
      }
      
      // Connect nodes
      if (volume && recorder) {
        volume.connect(recorder);
        recorder.connect(audioContext.destination);
      }
      
      // Send sample rate if WebSocket is connected
      if (ws && ws.readyState === WebSocket.OPEN) {
        ws.send(sampleRate.toString());
      }
      
      return true;
    } catch (error) {
      console.error('Error starting audio:', error);
      return false;
    }
  }

  // Stop audio streaming
  function stopAudio() {
    try {
      if (recorder && volume) {
        // Disconnect nodes
        recorder.disconnect();
        volume.disconnect();
        console.log('Audio nodes disconnected');
      }
      return true;
    } catch (error) {
      console.error('Error stopping audio:', error);
      return false;
    }
  }

  // Toggle audio streaming
  async function toggleStreaming() {
    const startButton = document.getElementById('startButton');
    
    if (!isListening) {
      // Start listening
      console.log('Starting audio streaming...');
      
      // Set up WebSocket first
      setupWebSocket();
      
      // Start audio streaming
      if (await startAudio()) {
        // Update state and UI
        isListening = true;
        startButton.classList.add('listening');
        startButton.textContent = 'Stop Listening';
        updateStatus('Listening for wake words');
        console.log('Audio streaming started');
      } else {
        updateStatus('Failed to start audio');
      }
    } else {
      // Stop listening
      console.log('Stopping audio streaming...');
      
      // Stop audio
      stopAudio();
      
      // Close WebSocket
      if (ws) {
        ws.close();
      }
      
      // Update state and UI
      isListening = false;
      isRecording = false;
      updateRecordingStatus(false);
      startButton.classList.remove('listening');
      startButton.textContent = 'Start Listening';
      updateStatus('Stopped');
      console.log('Audio streaming stopped');
    }
  }

  // Connect to WebSocket on page load
  setupWebSocket();

  // Add event listener to the start button
  document.getElementById('startButton').addEventListener('click', toggleStreaming);
  </script>
</body>
</html>