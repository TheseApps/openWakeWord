<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>openWakeWord Listening Client</title>
  <style>
    body {
      text-align: center;
      font-family: 'Roboto', sans-serif;
      max-width: 800px;
      margin: 0 auto;
      padding: 20px;
    }
    
    #startButton {
      padding: 15px 30px;
      font-size: 18px;
      background-color: #03A9F4;
      border: none;
      border-radius: 4px;
      color: white;
      cursor: pointer;
      outline: none;
      transition: background-color 0.3s;
    }
    
    #startButton.listening {
      background-color: #F44336;
    }
    
    #listenButton {
      padding: 15px 30px;
      font-size: 18px;
      background-color: #4CAF50;
      border: none;
      border-radius: 4px;
      color: white;
      cursor: pointer;
      outline: none;
      transition: background-color 0.3s;
      margin-left: 10px;
    }
    
    #listenButton.recording {
      background-color: #FF9800;
      animation: pulse 1s infinite;
    }
    
    @keyframes pulse {
      0% { opacity: 1; }
      50% { opacity: 0.7; }
      100% { opacity: 1; }
    }

    table {
      margin: 20px auto;
      border-collapse: collapse;
      width: 100%;
    }
    
    th, td {
      border: 1px solid #E0E0E0;
      padding: 10px;
      text-align: left;
    }
    
    th {
      background-color: #F5F5F5;
    }

    .status-display {
      margin: 20px 0;
      padding: 15px;
      border-radius: 4px;
      background-color: #F5F5F5;
      text-align: left;
    }
    
    .status-message {
      font-weight: bold;
      margin-bottom: 10px;
    }
    
    .log-area {
      height: 150px;
      overflow-y: auto;
      border: 1px solid #E0E0E0;
      padding: 10px;
      margin-top: 10px;
      text-align: left;
      font-family: monospace;
      background-color: #FAFAFA;
    }
    
    @keyframes fadeOut {
      from { opacity: 1; }
      to { opacity: 0; }
    }

    .detected-animation {
      animation: fadeOut 2s forwards;
    }
  </style>
</head>
<body>
  <h1>openWakeWord Continuous Listening</h1>
  <p>Click "Start Streaming" to connect to the server, then click "Start Listening" when ready to begin recording.</p>
  <p>Recording will stop automatically after: saying "ENGAGE!", a 2.5-second pause, or 12 seconds elapse.</p>
  
  <div>
    <button id="startButton">Start Streaming</button>
    <button id="listenButton" disabled>Start Listening</button>
  </div>
  
  <div class="status-display">
    <div class="status-message" id="statusMessage">Not connected</div>
    <div>Current state: <span id="currentState">Idle</span></div>
    <div class="log-area" id="logArea"></div>
  </div>

  <h2>Available Models</h2>
  <table>
    <tr>
      <th>Wakeword</th>
      <th>Status</th>
    </tr>
    <tr>
      <td></td>
      <td></td>
    </tr>
  </table>

  <script>
  // Utility function to log messages to the UI
  function logMessage(message) {
    const logArea = document.getElementById('logArea');
    const timestamp = new Date().toLocaleTimeString();
    const logEntry = document.createElement('div');
    logEntry.textContent = `${timestamp}: ${message}`;
    logArea.appendChild(logEntry);
    logArea.scrollTop = logArea.scrollHeight; // Auto-scroll to bottom
  }
  
  // Update the status message
  function updateStatus(message, state) {
    document.getElementById('statusMessage').textContent = message;
    document.getElementById('currentState').textContent = state;
  }
  
  // Create websocket connection
  let ws;
  let isStreamingActive = false;
  let isListening = false;
  
  // Connect to websocket
  function connectWebSocket() {
    ws = new WebSocket('ws://localhost:9000/ws');
    
    // When the websocket connection is open
    ws.onopen = function() {
      logMessage('WebSocket connection established');
      updateStatus('Connected to server', 'Ready');
      document.getElementById('listenButton').disabled = false;
      isStreamingActive = true;
    };
    
    // When the websocket connection is closed
    ws.onclose = function() {
      logMessage('WebSocket connection closed');
      updateStatus('Disconnected from server', 'Idle');
      document.getElementById('startButton').classList.remove('listening');
      document.getElementById('startButton').textContent = 'Start Streaming';
      document.getElementById('listenButton').disabled = true;
      isStreamingActive = false;
      isListening = false;
    };
    
    // When an error occurs with the websocket
    ws.onerror = function(error) {
      logMessage('WebSocket error occurred');
      console.error('WebSocket error:', error);
    };
    
    // Get responses from websocket and display information
    ws.onmessage = (event) => {
      let payload;
      try {
        payload = JSON.parse(event.data);
      } catch (e) {
        console.error("Failed to parse JSON:", e, "Raw data:", event.data);
        return;
      }
      
      // Handle model list
      if ("loaded_models" in payload) {
        logMessage(`Loaded ${payload.loaded_models.length} models`);
        
        // Add loaded models to the table
        const table = document.querySelector('table');
        const rows = table.querySelectorAll('tr');
        
        for (let i = 1; i < payload.loaded_models.length + 1; i++) {
          if (i < rows.length) {
            const row = rows[i];
            const cell = row.querySelectorAll('td')[0];
            cell.textContent = payload.loaded_models[i - 1];
          } else {
            // Insert extra rows if needed
            const row = table.insertRow();
            const cell1 = row.insertCell();
            const cell2 = row.insertCell();
            cell1.textContent = payload.loaded_models[i - 1];
            cell2.textContent = '';
          }
        }
      }
      
      // Handle status messages
      if ("status" in payload) {
        logMessage(`Status: ${payload.status} - ${payload.message}`);
        
        if (payload.status === "listening") {
          updateStatus(payload.message, 'Recording');
          document.getElementById('listenButton').classList.add('recording');
          isListening = true;
        } 
        else if (["timeout", "pause_detected", "engage_detected"].includes(payload.status)) {
          updateStatus(payload.message, 'Ready');
          document.getElementById('listenButton').classList.remove('recording');
          isListening = false;
        }
      }
      
      // Handle wake word activations
      if ("activations" in payload) {
        const table = document.querySelector('table');
        const rows = table.querySelectorAll('tr');
        
        for (let i = 1; i < rows.length; i++) {
          const modelCell = rows[i].querySelectorAll('td')[0];
          const modelName = modelCell.textContent;
          
          // Check if this model is in the received activations
          if (payload.activations.includes(modelName)) {
            logMessage(`Detected: ${modelName}`);
            
            // Update table cell visual
            const cell = rows[i].querySelectorAll('td')[1];
            cell.textContent = "Detected!";
            cell.classList.add('detected-animation');
            
            // Remove the CSS class after the animation ends
            cell.addEventListener('animationend', () => {
              cell.textContent = '';
              cell.classList.remove('detected-animation');
            }, { once: true });
          }
        }
      }
    };
  }
  
  // Audio streaming setup
  let audioStream;
  let audioContext;
  let recorder;
  let volume;
  let sampleRate;
  
  // Initialize audio components
  function initializeAudio() {
    navigator.mediaDevices.getUserMedia({audio: true})
      .then(function(stream) {
        audioStream = stream;
        
        // Create audio context
        const context = window.AudioContext || window.webkitAudioContext;
        audioContext = new context();
        
        // Get sample rate
        sampleRate = audioContext.sampleRate;
        
        // Create gain node
        volume = audioContext.createGain();
        
        // Create audio source
        const audioInput = audioContext.createMediaStreamSource(audioStream);
        
        // Connect source to gain
        audioInput.connect(volume);
        
        // Create script processor for audio processing
        const bufferSize = 4096;
        recorder = (audioContext.createScriptProcessor ||
                    audioContext.createJavaScriptNode).call(audioContext,
                                                           bufferSize,
                                                           1,
                                                           1);
        
        recorder.onaudioprocess = function(event) {
          // Only process if websocket is open and streaming is active
          if (ws && ws.readyState === WebSocket.OPEN && isStreamingActive) {
            const samples = event.inputBuffer.getChannelData(0);
            
            // Convert float32 to int16
            const PCM16iSamples = samples.map(sample => {
              let val = Math.floor(32767 * sample);
              return Math.min(32767, Math.max(-32768, val));
            });
            
            // Send audio data
            const int16Array = new Int16Array(PCM16iSamples);
            const blob = new Blob([int16Array], { type: 'application/octet-stream' });
            ws.send(blob);
          }
        };
        
        logMessage('Audio system initialized');
      })
      .catch(function(error) {
        console.error('Error capturing audio:', error);
        logMessage('Error capturing audio: ' + error.message);
        alert('Could not access microphone. Please check permissions.');
      });
  }
  
  // Start/stop audio streaming
  function toggleAudioStreaming() {
    if (!isStreamingActive) {
      // Start streaming
      connectWebSocket();
      
      if (!audioContext) {
        initializeAudio();
      } else if (audioContext.state === 'suspended') {
        audioContext.resume();
      }
      
      document.getElementById('startButton').textContent = 'Stop Streaming';
      document.getElementById('startButton').classList.add('listening');
    } else {
      // Stop streaming
      if (ws) {
        ws.close();
      }
      
      if (volume && recorder && audioContext) {
        recorder.disconnect();
        volume.disconnect();
      }
      
      document.getElementById('startButton').textContent = 'Start Streaming';
      document.getElementById('startButton').classList.remove('listening');
      document.getElementById('listenButton').classList.remove('recording');
      document.getElementById('listenButton').disabled = true;
    }
  }
  
  // Start listening command
  function startListening() {
    if (!isListening && ws && ws.readyState === WebSocket.OPEN) {
      // Connect audio nodes if needed
      if (volume && recorder && audioContext) {
        volume.connect(recorder);
        recorder.connect(audioContext.destination);
        
        // Send sample rate when first starting
        ws.send(sampleRate.toString());
        
        // Send start listening command
        ws.send(JSON.stringify({command: "start_listening"}));
      } else {
        logMessage('Audio system not ready');
      }
    } else if (isListening) {
      logMessage('Already listening');
    } else {
      logMessage('WebSocket not connected');
    }
  }
  
  // Event listeners
  document.getElementById('startButton').addEventListener('click', toggleAudioStreaming);
  document.getElementById('listenButton').addEventListener('click', startListening);
  </script>
</body>
</html> 